{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haasithp/Image-Generation/blob/main/image_gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1qExCe654lb"
      },
      "source": [
        "### Install Cascade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-25T10:20:11.403466Z",
          "iopub.status.busy": "2024-02-25T10:20:11.403063Z",
          "iopub.status.idle": "2024-02-25T10:24:16.567675Z",
          "shell.execute_reply": "2024-02-25T10:24:16.566251Z",
          "shell.execute_reply.started": "2024-02-25T10:20:11.403434Z"
        },
        "id": "oIZNNOKOrRdz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# ## If running on Colab\n",
        "# %cd /content/\n",
        "# !git lfs install\n",
        "# !git clone https://huggingface.co/spaces/multimodalart/stable-cascade\n",
        "# %cd /content/stable-cascade\n",
        "# !pip install -r /content/stable-cascade/requirements.txt\n",
        "# !pip3 uninstall torch torchvision torchaudio -y\n",
        "# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "# !pip uninstall torchdata torchtext -y\n",
        "# !pip install torchdata torchtext\n",
        "\n",
        "\n",
        "### If running on Kaggle\n",
        "%cd /kaggle/working/\n",
        "!git lfs install\n",
        "!git clone https://huggingface.co/spaces/multimodalart/stable-cascade\n",
        "%cd /kaggle/working/stable-cascade\n",
        "!pip install -r /kaggle/working/stable-cascade/requirements.txt\n",
        "!pip3 uninstall torch torchvision torchaudio -y\n",
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip uninstall torchdata torchtext -y\n",
        "!pip install torchdata torchtext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RspPntQA5xWS"
      },
      "source": [
        "## Load Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-25T10:24:16.570572Z",
          "iopub.status.busy": "2024-02-25T10:24:16.570122Z",
          "iopub.status.idle": "2024-02-25T10:26:10.290366Z",
          "shell.execute_reply": "2024-02-25T10:26:10.289159Z",
          "shell.execute_reply.started": "2024-02-25T10:24:16.570536Z"
        },
        "id": "_cJn2VdMruLO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from diffusers import StableCascadeDecoderPipeline, StableCascadePriorPipeline\n",
        "from diffusers.utils import numpy_to_pil\n",
        "\n",
        "# Ensure that the environment is set up and the models are loaded properly\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # Check if GPU is available\n",
        "dtype = torch.bfloat16 if torch.cuda.is_available() else torch.float32  # Define data type based on GPU availability\n",
        "\n",
        "# Initialize Stable Cascade Prior and Decoder Pipelines\n",
        "# Replace 'stabilityai/stable-cascade-prior' and 'stabilityai/stable-cascade' with the actual model names or paths\n",
        "prior_pipeline = StableCascadePriorPipeline.from_pretrained(\"stabilityai/stable-cascade-prior\", torch_dtype=dtype).to(device)\n",
        "decoder_pipeline = StableCascadeDecoderPipeline.from_pretrained(\"stabilityai/stable-cascade\", torch_dtype=dtype).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pz0-vZNc6PkB"
      },
      "source": [
        "### Generating Image with a resolution of 512x512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-25T10:26:10.293736Z",
          "iopub.status.busy": "2024-02-25T10:26:10.292495Z"
        },
        "id": "yJsuC-Jz5Cj2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import re\n",
        "\n",
        "Random_seed = random.randint(0, 6969)  # Generate a random seed for reproducibility\n",
        "\n",
        "def generate_image(prompt, seed=Random_seed, width=1024, height=1024, prior_guidance_scale=7.5, decoder_guidance_scale=0.0, num_inference_steps=50, num_images_per_prompt=1):\n",
        "    Random_seed = random.randint(0, 6969)  # Generate a new random seed for each function call\n",
        "    generator = torch.Generator(device=device).manual_seed(seed)\n",
        "\n",
        "    # Generate with Prior\n",
        "    prior_results = prior_pipeline(\n",
        "        prompt=prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=prior_guidance_scale,\n",
        "        num_images_per_prompt=num_images_per_prompt,\n",
        "        generator=generator\n",
        "    )\n",
        "\n",
        "    # Extract image embeddings from the generator object\n",
        "    image_embeddings = None\n",
        "    for result in prior_results:\n",
        "        if 'image_embeddings' in result:\n",
        "            image_embeddings = result['image_embeddings']\n",
        "            break\n",
        "\n",
        "    if image_embeddings is None:\n",
        "        raise ValueError(\"Failed to generate image embeddings from the prior pipeline\")\n",
        "\n",
        "    # Generate with Decoder\n",
        "    decoder_output = decoder_pipeline(\n",
        "        image_embeddings=image_embeddings,\n",
        "        prompt=prompt,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=decoder_guidance_scale,\n",
        "        num_images_per_prompt=num_images_per_prompt,\n",
        "        generator=generator,\n",
        "        output_type=\"pil\"\n",
        "    )\n",
        "\n",
        "    return decoder_output.images[0]  # Returns the first generated image\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    prompt = \"An elegant woman wearing a flowing red dress stands on a cobblestone street lined with historic buildings. The sun sets behind her, casting a warm glow over the scene. In the distance, a quaint caf√© with outdoor seating adds to the picturesque ambiance. The woman's confident posture exudes sophistication, while her expression hints at a sense of wanderlust and adventure\"\n",
        "    Random_seed = random.randint(0, 6969)\n",
        "\n",
        "    # Sanitize the prompt\n",
        "    safe_prompt = re.sub(r'[^\\w\\s-]', '', prompt)[:50].strip().replace(' ', '_')\n",
        "\n",
        "    # Generate the image\n",
        "    image = generate_image(prompt, num_images_per_prompt=1, seed=Random_seed, width=512, height=512, prior_guidance_scale=7.5, decoder_guidance_scale=0.0, num_inference_steps=50)\n",
        "    image.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybvLhy6J83hq"
      },
      "source": [
        "#### Import necessary libraries for stable-diffusion-x4-upscaler\n",
        "##### This upscales the image by 4 times\n",
        "##### This is running on CPU\n",
        "##### To change it to GPU, uncomment the required cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVffIwl6qJ2W",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from diffusers import StableDiffusionUpscalePipeline\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_58kSisEqKyE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#CPU\n",
        "# load model and scheduler\n",
        "model_id = \"stabilityai/stable-diffusion-x4-upscaler\"\n",
        "pipeline = StableDiffusionUpscalePipeline.from_pretrained(\n",
        "    model_id, revision=\"fp16\", torch_dtype=torch.float32\n",
        ")\n",
        "pipeline = pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #GPU\n",
        "# # load model and scheduler\n",
        "# model_id = \"stabilityai/stable-diffusion-x4-upscaler\"\n",
        "# pipeline = StableDiffusionUpscalePipeline.from_pretrained(\n",
        "#     model_id, revision=\"fp16\", torch_dtype=torch.float16\n",
        "# ).to('cuda')\n",
        "# pipeline = pipeline"
      ],
      "metadata": {
        "id": "qpFoUKZ29VRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G27VEjMapyM9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Extract filename from the prompt\n",
        "filename_from_prompt = re.sub(r'[^\\w\\s-]', '', prompt)[:50].strip().replace(' ', '_')\n",
        "# Define the filename for the upscaled image\n",
        "upscaled_filename = f\"{filename_from_prompt}_upscaled.png\"\n",
        "upscaled_image = pipeline(prompt=prompt, image=image).images[0]\n",
        "upscaled_image.save(upscaled_filename)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "s1qExCe654lb"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30646,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}